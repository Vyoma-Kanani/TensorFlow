{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAR+j2yO7xY5U5uOzo/Gqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-Kanani/TensorFlow/blob/main/Mnist_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJgngld-BLik"
      },
      "source": [
        "# MNIST Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEETVIYYfhAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dca1028-528f-4e06-c4c1-0030efe38590"
      },
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.30.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.2.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.1.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (56.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZooEH_fr-dyL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1QZNBsgjAhD"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOFjwqM79W7Y",
        "outputId": "3ae1bc0a-d507-45aa-c712-511ca8b320db"
      },
      "source": [
        "# Alternative to Load Dataset through tensorflow_datasets\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    # Same as tensorflow dataset catalog\n",
        "    \"mnist\",\n",
        "    # If validation then add that as well\n",
        "    split=[\"train\", \"test\"],\n",
        "    # So that it doesnot see the exact same sequence of the data\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
        "    with_info=True,  # able to get info about dataset\n",
        ")\n",
        "\n",
        "ds_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='mnist',\n",
              "    version=3.0.1,\n",
              "    description='The MNIST database of handwritten digits.',\n",
              "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
              "    }),\n",
              "    total_num_examples=70000,\n",
              "    splits={\n",
              "        'test': 10000,\n",
              "        'train': 60000,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{lecun2010mnist,\n",
              "      title={MNIST handwritten digit database},\n",
              "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
              "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
              "      volume={2},\n",
              "      year={2010}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0-8rKCCi-xeg",
        "outputId": "2f4944c4-4f8a-46c0-ceb7-6dfca9635d2e"
      },
      "source": [
        "# We have to set as_supervised as False\n",
        "# fig = tfds.show_examples(ds_train, ds_info, rows=4, cols=4)\n",
        "# print(ds_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.1,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7YHHcTxf85l",
        "outputId": "2b30ab93-5d49-44a7-f605-05133165776f"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYDo4Kg3j0TA"
      },
      "source": [
        "So there are 60000 images with 28*28 pixsel.<br>\n",
        "As we are gonna send them to neural network v require 1 column with those feature value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDoROG9Hji_F"
      },
      "source": [
        "# As we want to keep those 60000 values as it is so -1 and we have flatten 2 dimensions 28*28 = 784 \n",
        "# The data are gonna be numpy arrays\n",
        "# Also Normalize the value so rather than being from 0 to 255 it should be between 0 and 1\n",
        "\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "\n",
        "# Can also do\n",
        "# x_train = tf.convert_to_tensor(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn8TxTR0kO9w"
      },
      "source": [
        "## Models\n",
        "### Sequential API (Very convenient but not very flexible )\n",
        "It only allows you to have one input maps to one output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbFydNMjIxcF",
        "outputId": "e94ae726-c56d-4203-d830-a5b14b51bf81"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "      keras.Input(shape=(28*28)), #To get the summary of model\n",
        "      layers.Dense(512, activation=\"relu\"),    # Dense is for fully connected layer    \n",
        "      layers.Dense(256, activation='relu', name='SecondLayer'),\n",
        "      layers.Dense(10) #for output and activation is Soft Max which is going to be handled by loss function\n",
        "    #  If we mention activition function i.e softmax here then from_logits will be false else true\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Alternative of above code Here we can write inbetwwen model.summary to get the info \n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(784)))\n",
        "model.add(layers.Dense(512, activation=\"relu\"))\n",
        "model.add(layers.Dense(256, activation=\"relu\", name=\"my_layer\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "# To extract specific layer output which helps during debugging\n",
        "model = keras.Model(inputs = model.inputs, outputs = [model.layers[-1].output]) \n",
        "# Here -1 means the last layer, -2 will be the last second layer and so on \n",
        "\n",
        "# Can even access layer through name\n",
        "model = keras.Model(inputs = model.inputs, outputs = [model.get_layer('my_layer').output])\n",
        "\n",
        "# This is for the specific we send in\n",
        "feature = model.predict(x_train)\n",
        "print(feature.shape)\n",
        "# It will print 60000,256\n",
        "\n",
        "# To get all layers\n",
        "model = keras.Model(inputs = model.inputs, outputs = [layer.output for layer in model.layers] )\n",
        "\n",
        "features = model.predict(x_train)\n",
        "for feature in features:\n",
        "  print(feature.shape)\n",
        "\n",
        "# If we remove keras.Input then we could not print summary here insted we can but after model.fit onen the connection is send to model \n",
        "print(model.summary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 256)\n",
            "(60000, 784)\n",
            "(60000, 512)\n",
            "(60000, 256)\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "my_layer (Dense)             (None, 256)               131328    \n",
            "=================================================================\n",
            "Total params: 533,248\n",
            "Trainable params: 533,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf6RWBfgSQst"
      },
      "source": [
        "### Functional API (A bit more flexible)\n",
        "Handel multiple input and multiple output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSa7eu4tScar",
        "outputId": "e230348e-8b71-4557-cd90-89e8cd023115"
      },
      "source": [
        "input = keras.Input(shape=(28*28))\n",
        "x= layers.Dense(512, activation='relu', name='First_layer')(input)  #Basically we are connecting input layer with x\n",
        "x= layers.Dense(256,activation='relu', name='Second_layer')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "# If we mention activition in output layer we have to set from_logits = False which is also default argument\n",
        "\n",
        "model = keras.Model(inputs=input, outputs = outputs)\n",
        "\n",
        "print(model.summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7fd1c7fa7a90>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qbieNz-66U"
      },
      "source": [
        "#### Using SGD (Stochastic Gradient Descent) as optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oj2xlAqXJtE",
        "outputId": "1a632844-b393-49ee-a9ac-f6ed0e79724c"
      },
      "source": [
        "# How to configure the training part of the network\n",
        "# This specifies the network configuration\n",
        "model.compile(\n",
        "    #As we did logit = true its going to send it in to a soft max first and then it is going to map it to SparseCategoricalCrossentropy  \n",
        "    # SparseCategoricalCrossentropy is for numerical categorical if we only write CategorialCrossentropy then we have to use Onehotencoding\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "    # optimizer = keras.optimizers.Adam(lr=0.001),  #learning rate\n",
        "    # Using Different optimizers\n",
        "    optimizer = keras.optimizers.SGD(lr=0.001),\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "#Defines concrete training of the network\n",
        "model.fit(x_train, y_train,  batch_size = 32, epochs = 5, verbose = 2 )\n",
        "\n",
        "# After Training lets test it \n",
        "model.evaluate(x_test, y_test, batch_size = 32, verbose = 2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 8s - loss: 1.6565 - accuracy: 0.6084\n",
            "Epoch 2/5\n",
            "1875/1875 - 8s - loss: 0.7922 - accuracy: 0.8337\n",
            "Epoch 3/5\n",
            "1875/1875 - 8s - loss: 0.5440 - accuracy: 0.8673\n",
            "Epoch 4/5\n",
            "1875/1875 - 8s - loss: 0.4509 - accuracy: 0.8833\n",
            "Epoch 5/5\n",
            "1875/1875 - 8s - loss: 0.4013 - accuracy: 0.8924\n",
            "313/313 - 1s - loss: 0.3637 - accuracy: 0.9036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3636521100997925, 0.9035999774932861]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDvQSC__dD9"
      },
      "source": [
        "#### Using Adagrad (Adaptive Gradient Algorithm) as optimizer\n",
        "Adaptive Gradient Algorithm (Adagrad) is an algorithm for gradient-based optimization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4aYdHDj_i9G",
        "outputId": "1ccc940f-8f9d-4805-dc5c-a77b2563e7af"
      },
      "source": [
        "model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "    optimizer = keras.optimizers.Adagrad(lr=0.001),  #learning rate\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,  batch_size = 32, epochs = 5, verbose = 2 )\n",
        "model.evaluate(x_test, y_test, batch_size = 32, verbose = 2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 9s - loss: 0.0159 - accuracy: 0.9954\n",
            "Epoch 2/5\n",
            "1875/1875 - 9s - loss: 0.0125 - accuracy: 0.9964\n",
            "Epoch 3/5\n",
            "1875/1875 - 9s - loss: 0.0110 - accuracy: 0.9969\n",
            "Epoch 4/5\n",
            "1875/1875 - 9s - loss: 0.0099 - accuracy: 0.9973\n",
            "Epoch 5/5\n",
            "1875/1875 - 9s - loss: 0.0092 - accuracy: 0.9975\n",
            "313/313 - 1s - loss: 0.0629 - accuracy: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06293357163667679, 0.9825999736785889]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnqzEl43ACtO"
      },
      "source": [
        "#### Using RMSprop as Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5M1MBHKAO_B",
        "outputId": "a3e51452-9b8c-452c-a1e2-c5a369dc9435"
      },
      "source": [
        "model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "    optimizer = keras.optimizers.RMSprop(lr=0.001),  #learning rate\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,  batch_size = 32, epochs = 5, verbose = 2 )\n",
        "model.evaluate(x_test, y_test, batch_size = 32, verbose = 2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 14s - loss: 0.0153 - accuracy: 0.9956\n",
            "Epoch 2/5\n",
            "1875/1875 - 13s - loss: 0.0127 - accuracy: 0.9969\n",
            "Epoch 3/5\n",
            "1875/1875 - 13s - loss: 0.0111 - accuracy: 0.9973\n",
            "Epoch 4/5\n",
            "1875/1875 - 13s - loss: 0.0106 - accuracy: 0.9975\n",
            "Epoch 5/5\n",
            "1875/1875 - 13s - loss: 0.0078 - accuracy: 0.9981\n",
            "313/313 - 1s - loss: 0.1532 - accuracy: 0.9842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15321926772594452, 0.9842000007629395]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVmP1lAK_Iz2"
      },
      "source": [
        "#### Using Adam as Optimizer\n",
        "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5HeJzLYyuH",
        "outputId": "d9d7d453-a5be-4b09-d823-37087aca1a41"
      },
      "source": [
        "model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "    optimizer = keras.optimizers.Adam(lr=0.001),  #learning rate\n",
        "    metrics = [\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,  batch_size = 32, epochs = 5, verbose = 2 )\n",
        "model.evaluate(x_test, y_test, batch_size = 32, verbose = 2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 10s - loss: 0.1695 - accuracy: 0.9491\n",
            "Epoch 2/5\n",
            "1875/1875 - 9s - loss: 0.0780 - accuracy: 0.9751\n",
            "Epoch 3/5\n",
            "1875/1875 - 9s - loss: 0.0538 - accuracy: 0.9825\n",
            "Epoch 4/5\n",
            "1875/1875 - 9s - loss: 0.0398 - accuracy: 0.9871\n",
            "Epoch 5/5\n",
            "1875/1875 - 9s - loss: 0.0330 - accuracy: 0.9896\n",
            "313/313 - 1s - loss: 0.0797 - accuracy: 0.9785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07970888167619705, 0.9785000085830688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vdBIg2kAlZn"
      },
      "source": [
        "Comparing SGD, Adagrad, RMSprop, and Adam it is seen that for MNIST dataset the model with highest accuracy is obtained using RMSprop optimizer.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDrx6Lsy31AW"
      },
      "source": [
        "## RNNs, GRUs, LSTMs and Bidirectionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5a3wgYG_VIU"
      },
      "source": [
        "Reloding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bihSCyNa_VfO"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape([-1, 28, 28]).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape([-1, 28, 28]).astype(\"float32\") / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bhNbwaE-PIx"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrlbreRU3zz4",
        "outputId": "6754112c-8f1c-4fd1-cc08-d77978bfe733"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28))) #We dont to have a specific number of time step we dont need to specify that dementions\n",
        "model.add(\n",
        "    # It will return the output for each time step. In that way we can stack multiple RNN layers on top of each other.\n",
        "    # Here we are going to have 28 time step\n",
        "    layers.SimpleRNN(256, return_sequences=True, activation='tanh'),\n",
        ")\n",
        "model.add(layers.SimpleRNN(256, activation='tanh'))\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f617928f590>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6TjtzVN-RH-"
      },
      "source": [
        "### GRU\n",
        "\n",
        "This should work better than Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy1Rtmk8-UT8",
        "outputId": "6f0c4727-0a9c-4c61-9467-5ce76bb2a6c7"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28))) #We dont to have a specific number of time step we dont need to specify that dementions\n",
        "model.add(\n",
        "    layers.GRU(256, return_sequences=True, activation='tanh'),\n",
        ")\n",
        "model.add(layers.GRU(256, activation='tanh'))\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f6176e9f590>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkzvfXbL_sGa"
      },
      "source": [
        "### LSTMs\n",
        "\n",
        "A little better than GRUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Z8PS4dAG4J"
      },
      "source": [
        "One Directional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p33KzJU_vAp",
        "outputId": "b2390cae-e5e3-471d-ebdf-0f6d964539c1"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28))) #We dont to have a specific number of time step we dont need to specify that dementions\n",
        "model.add(\n",
        "    layers.LSTM(256, return_sequences=True, activation='tanh'),\n",
        ")\n",
        "model.add(layers.LSTM(256, activation='tanh'))\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f61793fc710>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjassjfuAI0J"
      },
      "source": [
        "Bidirectional LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOVkf9p3AMQd"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28))) #We dont to have a specific number of time step we dont need to specify that dementions\n",
        "model.add(\n",
        "    # We are specifying number of nodes for each hidden state i.e 256\n",
        "    layers.Bidirectional(\n",
        "        layers.LSTM(256, return_sequences=True, activation='tanh'),\n",
        "    )\n",
        "    # We are going to get 512 nodes instead of 256\n",
        "    # One going Forward and One going Backward\n",
        ")\n",
        "model.add(\n",
        "    layers.Bidirectional(\n",
        "      layers.LSTM(256, activation='tanh')    \n",
        "    )\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM7cD-S6-ckR",
        "outputId": "c0da9062-91ad-4263-d37b-cd758b682459"
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 - 278s - loss: 0.3075 - accuracy: 0.8990\n",
            "Epoch 2/10\n",
            "938/938 - 271s - loss: 0.0838 - accuracy: 0.9743\n",
            "Epoch 3/10\n",
            "938/938 - 273s - loss: 0.0583 - accuracy: 0.9820\n",
            "Epoch 4/10\n",
            "938/938 - 277s - loss: 0.0452 - accuracy: 0.9857\n",
            "Epoch 5/10\n",
            "938/938 - 286s - loss: 0.0388 - accuracy: 0.9877\n",
            "Epoch 6/10\n",
            "938/938 - 284s - loss: 0.0326 - accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "938/938 - 274s - loss: 0.0289 - accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "938/938 - 277s - loss: 0.0231 - accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "938/938 - 275s - loss: 0.0193 - accuracy: 0.9939\n",
            "Epoch 10/10\n",
            "938/938 - 279s - loss: 0.0203 - accuracy: 0.9936\n",
            "157/157 - 14s - loss: 0.0356 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0355784110724926, 0.9900000095367432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXrtqyJYD1KJ"
      },
      "source": [
        "---\n",
        "## Model Subclassing\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MURRF7DqD7ly"
      },
      "source": [
        "Reloding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12_IZoB-hf4"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Here we are adding Number of Channels\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v66o-7HQgVjK"
      },
      "source": [
        "Common Structure is <br>\n",
        "CNN -> BatchNorm -> ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8a4t2W2EFs6"
      },
      "source": [
        "class CNNBlock(layers.Layer):\n",
        "  # Here layers is going to keep track of everything under the hood for doing back propogation and all\n",
        "\n",
        "  def __init__(self, out_channels, kernel_size = 3):\n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.conv = layers.Conv2D(out_channels, kernel_size, padding= 'same')\n",
        "    self.bn = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor, training = False):\n",
        "    x = self.conv(input_tensor)\n",
        "    x = self.bn(x, training = training)\n",
        "    x = tf.nn.relu(x)\n",
        "    return x \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FUPKjAGGcs-"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "     CNNBlock(32),\n",
        "     CNNBlock(64),\n",
        "     CNNBlock(128),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(10),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9Pbpo5pgw5"
      },
      "source": [
        "Simpling compiling using model subclass "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si2otr94g76T",
        "outputId": "25035a2c-d0f1-44c7-b615-72daf001a21a"
      },
      "source": [
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy'], \n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=3, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "938/938 - 623s - loss: 0.5802 - accuracy: 0.9467\n",
            "Epoch 2/3\n",
            "938/938 - 624s - loss: 0.1009 - accuracy: 0.9813\n",
            "Epoch 3/3\n",
            "938/938 - 616s - loss: 0.0352 - accuracy: 0.9894\n",
            "157/157 - 25s - loss: 0.0594 - accuracy: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0593649223446846, 0.9843000173568726]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9RGIYPMlFWg"
      },
      "source": [
        "Creating a Resedual Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID_bHLHxlLqw"
      },
      "source": [
        "class ResBlock(layers.Layer):\n",
        "    def __init__(self, channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.channels = channels\n",
        "        # There are 3 blocks and each block is CNN, a batchnorm and ReLU\n",
        "        self.cnn1 = CNNBlock(channels[0], 3)\n",
        "        self.cnn2 = CNNBlock(channels[1], 3)\n",
        "        self.cnn3 = CNNBlock(channels[2], 3)\n",
        "        # MaxPooling is for inpute size the height and width\n",
        "        self.pooling = layers.MaxPooling2D()\n",
        "        # To have same number of channels\n",
        "        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.cnn1(input_tensor, training=training)\n",
        "        x = self.cnn2(x, training=training)\n",
        "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
        "        x = self.pooling(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZia31zPnHiP"
      },
      "source": [
        "To have a final model we inherit keras.Model\n",
        "<br>\n",
        "Which can have the functionality of fit i.e training a model, evaluating a model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7I4WcEynHyg"
      },
      "source": [
        "class ResNet_Like(keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet_Like, self).__init__()\n",
        "        # Specifying number of channels for each of the CNN block in this RES block\n",
        "        self.block1 = ResBlock([32, 32, 64])\n",
        "        self.block2 = ResBlock([128, 128, 256])\n",
        "        self.block3 = ResBlock([128, 256, 512])\n",
        "        # Average pool height and Width can also use layers.Flatten()\n",
        "        self.pool = layers.GlobalAveragePooling2D()\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.block1(input_tensor, training=training)\n",
        "        x = self.block2(x, training=training)\n",
        "        x = self.block3(x, training=training)\n",
        "        x = self.pool(x, training=training)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    # This will overwrite the model call. To get output shape\n",
        "    def model(self):\n",
        "        x = keras.Input(shape=(28, 28, 1))\n",
        "        return keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vgQYZouhix5",
        "outputId": "b45023ee-c650-4caa-f6f8-b497ab8250a2"
      },
      "source": [
        "model = ResNet_Like().model()\n",
        "base_input = model.layers[0].input\n",
        "base_output = model.layers[2].output\n",
        "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
        "model = keras.Model(base_input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 - 1029s - loss: 0.1030 - accuracy: 0.9690\n",
            "157/157 - 46s - loss: 0.0375 - accuracy: 0.9869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as cnn_block_3_layer_call_and_return_conditional_losses, cnn_block_3_layer_call_fn, cnn_block_4_layer_call_and_return_conditional_losses, cnn_block_4_layer_call_fn, cnn_block_5_layer_call_and_return_conditional_losses while saving (showing 5 of 70). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as cnn_block_3_layer_call_and_return_conditional_losses, cnn_block_3_layer_call_fn, cnn_block_4_layer_call_and_return_conditional_losses, cnn_block_4_layer_call_fn, cnn_block_5_layer_call_and_return_conditional_losses while saving (showing 5 of 70). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: pretrained/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: pretrained/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReelYJPDrbGn"
      },
      "source": [
        "---\n",
        "### Custom Layer\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzdc4g7orvZl"
      },
      "source": [
        "Reloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ81GJr_qgMa"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8W4kgEGs3rh"
      },
      "source": [
        "Creating a Custom Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWM57yLSs8uk"
      },
      "source": [
        "class Dense(layers.Layer):\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(Dense, self).__init__()\n",
        "        # initializing Weight \n",
        "        self.w = self.add_weight(\n",
        "            # name is for saving and loading models\n",
        "            name=\"w\",\n",
        "            # input demention is the number of nodes we have and the unit is the nodes we are going to map it to. So when we are mapping the layer to 64 the unit is 64\n",
        "            shape=(input_dim, units),\n",
        "            initializer=\"random_normal\",\n",
        "            # For the case where some parameters are not trainable. Here all the parameters are trainable\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name=\"b\", shape=(units,), initializer=\"zeros\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkC08e0tu0dL"
      },
      "source": [
        "Now to call the dense layer inside MyModel we use self.dense1 = Dense(64,784) <br>\n",
        "Now to run the layer regardless of mentioning dimentions\n",
        "<br>So to avoide mentioning the input part while calling Dense lets use build method  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bc0bZiTtT85"
      },
      "source": [
        "class Dense(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(Dense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            name=\"w\",\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            name=\"b\", shape=(self.units,), initializer=\"random_normal\", trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH1lIBOOvoug"
      },
      "source": [
        "Creating Custom ReLU layer as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9lfvyDsvstg"
      },
      "source": [
        "class MyReLU(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MyReLU, self).__init__()\n",
        "\n",
        "    def call(self, x):\n",
        "        return tf.math.maximum(x, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR7gT_Fdr79r"
      },
      "source": [
        "class MyModel(keras.Model):  # model.fit, model.evalute, model.predict\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Creating 2 Dense layers \n",
        "        self.dense1 = Dense(64)\n",
        "        self.dense2 = Dense(num_classes)\n",
        "        self.relu = MyReLU()\n",
        "\n",
        "        # self.dense1 = layers.Dense(64)\n",
        "        # self.dense3 = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.relu(self.dense1(x))\n",
        "        return self.dense2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5-5JRprsk6M",
        "outputId": "9260d22f-e9c4-4127-a9ee-d649bc178d1b"
      },
      "source": [
        "model = MyModel()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 - 2s - loss: 0.3481 - accuracy: 0.9037\n",
            "Epoch 2/20\n",
            "1875/1875 - 2s - loss: 0.1671 - accuracy: 0.9518\n",
            "Epoch 3/20\n",
            "1875/1875 - 2s - loss: 0.1204 - accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "1875/1875 - 2s - loss: 0.0944 - accuracy: 0.9722\n",
            "Epoch 5/20\n",
            "1875/1875 - 2s - loss: 0.0765 - accuracy: 0.9769\n",
            "Epoch 6/20\n",
            "1875/1875 - 2s - loss: 0.0641 - accuracy: 0.9806\n",
            "Epoch 7/20\n",
            "1875/1875 - 2s - loss: 0.0546 - accuracy: 0.9837\n",
            "Epoch 8/20\n",
            "1875/1875 - 2s - loss: 0.0461 - accuracy: 0.9857\n",
            "Epoch 9/20\n",
            "1875/1875 - 2s - loss: 0.0402 - accuracy: 0.9883\n",
            "Epoch 10/20\n",
            "1875/1875 - 2s - loss: 0.0348 - accuracy: 0.9892\n",
            "Epoch 11/20\n",
            "1875/1875 - 2s - loss: 0.0303 - accuracy: 0.9907\n",
            "Epoch 12/20\n",
            "1875/1875 - 2s - loss: 0.0260 - accuracy: 0.9921\n",
            "Epoch 13/20\n",
            "1875/1875 - 2s - loss: 0.0233 - accuracy: 0.9930\n",
            "Epoch 14/20\n",
            "1875/1875 - 2s - loss: 0.0199 - accuracy: 0.9943\n",
            "Epoch 15/20\n",
            "1875/1875 - 2s - loss: 0.0183 - accuracy: 0.9948\n",
            "Epoch 16/20\n",
            "1875/1875 - 2s - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 17/20\n",
            "1875/1875 - 2s - loss: 0.0140 - accuracy: 0.9960\n",
            "Epoch 18/20\n",
            "1875/1875 - 2s - loss: 0.0126 - accuracy: 0.9965\n",
            "Epoch 19/20\n",
            "1875/1875 - 2s - loss: 0.0122 - accuracy: 0.9963\n",
            "Epoch 20/20\n",
            "1875/1875 - 2s - loss: 0.0101 - accuracy: 0.9972\n",
            "313/313 - 0s - loss: 0.1094 - accuracy: 0.9735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10938333719968796, 0.9735000133514404]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lei4-2-xNG8"
      },
      "source": [
        "### Saving and Loading Models\n",
        "\n",
        "\n",
        "*   To Save a Model weight \n",
        "*   Save and Load Entire Model (Serializing Model)\n",
        "  * Save Witghts\n",
        "  * Model Architecture\n",
        "  * Training Configuration (model.compile)\n",
        "  * Optimizers and states \n",
        "\n",
        "  So when we are saving and Loading entire model it is going to save as a data structure that means it can be loaded on different tensorflow frameworks like tensorflow Javascript, tensorflow Lite. We don't need to do any conversion  \n",
        "\n",
        "So after eveluating we can append the code for saving.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYjevkKOweST"
      },
      "source": [
        "# model.save_weights('foldername')\n",
        "# To save entire model\n",
        "# model.save('folderName')\n",
        "\n",
        "# To load the model which is entirely saved\n",
        "# model = keras.models.load_model('foldername')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}